{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1de8109-8c10-4e57-816f-fe2517eac47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Swish activation\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "# Feed Forward Module\n",
    "class FeedForwardModule(nn.Module):\n",
    "    def __init__(self, dim, expansion=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.linear1 = nn.Linear(dim, dim * expansion)\n",
    "        self.activation = swish\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim * expansion, dim)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.layernorm(x)\n",
    "        x = self.linear1(x_norm)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return x\n",
    "\n",
    "# Multi-Head Self-Attention Module\n",
    "class MultiHeadSelfAttentionModule(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.layernorm(x)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        return self.dropout(attn_out)\n",
    "\n",
    "# Convolution Module\n",
    "class ConvolutionModule(nn.Module):\n",
    "    def __init__(self, dim, kernel_size=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.pointwise_conv1 = nn.Conv1d(dim, 2 * dim, kernel_size=1)\n",
    "        self.glu = nn.GLU(dim=1)\n",
    "        self.depthwise_conv = nn.Conv1d(dim, dim, kernel_size=kernel_size, padding=kernel_size // 2, groups=dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(dim)\n",
    "        self.activation = swish\n",
    "        self.pointwise_conv2 = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layernorm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.pointwise_conv1(x)\n",
    "        x = self.glu(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pointwise_conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x.transpose(1, 2)\n",
    "\n",
    "# Conformer Block\n",
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=8, ff_expansion=4, conv_kernel=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ffn1 = FeedForwardModule(dim, ff_expansion, dropout)\n",
    "        self.mhsa = MultiHeadSelfAttentionModule(dim, heads, dropout)\n",
    "        self.conv = ConvolutionModule(dim, conv_kernel, dropout)\n",
    "        self.ffn2 = FeedForwardModule(dim, ff_expansion, dropout)\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + 0.5 * self.ffn1(x)\n",
    "        x = x + self.mhsa(x)\n",
    "        x = x + self.conv(x)\n",
    "        x = x + 0.5 * self.ffn2(x)\n",
    "        return self.layernorm(x)\n",
    "\n",
    "# Subsampling Module (Conv2D based)\n",
    "class ConvSubsampling(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(out_dim * ((80 // 4)), out_dim)  # Assuming input feature dim is 80\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (B, 1, T, F)\n",
    "        x = self.conv(x)  # (B, C, T//4, F//4)\n",
    "        b, c, t, f = x.size()\n",
    "        x = x.transpose(1, 2).contiguous().view(b, t, c * f)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Conformer Encoder\n",
    "class ConformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=80, num_layers=4, model_dim=256, heads=8, ff_expansion=4, conv_kernel=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.subsampling = ConvSubsampling(out_dim=model_dim)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConformerBlock(model_dim, heads, ff_expansion, conv_kernel, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.subsampling(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "# Decoder\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=256, hidden_dim=512, vocab_size=1000):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)\n",
    "\n",
    "# Full Conformer Transducer Model\n",
    "class ConformerTransducer(nn.Module):\n",
    "    def __init__(self, input_dim=80, encoder_layers=4, model_dim=256, heads=8, vocab_size=1000):\n",
    "        super().__init__()\n",
    "        self.encoder = ConformerEncoder(input_dim=input_dim, num_layers=encoder_layers, model_dim=model_dim, heads=heads)\n",
    "        self.decoder = LSTMDecoder(input_dim=model_dim, hidden_dim=model_dim * 2, vocab_size=vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        output = self.decoder(encoded)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442a50b-c9a6-4b66-a73a-a58b1f4e4317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sol3",
   "language": "python",
   "name": "sol3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
